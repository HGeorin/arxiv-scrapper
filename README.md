# cs-scrapper

## 说明

### 主要功能

爬取arxiv计算机科学相关的论文信息爬取到mongoDB数据库中，包括arXivId、标题、摘要、提交日期等字段

### 细节
- 脚本实现两个任务，首先爬取昨日的论文信息，再从存档点向后爬取论文信息（如2025-02-17，2020-02-16...)
- 查看日志:已实现简易日志，可查看存入论文信息数量以及task2执行到的时间点

## 使用方式

### 准备工作

- 部署mongoDB服务器，并在scrapper.py中硬编码mongoDB配置，(ip:port，数据库名和表名)，若数据库不在内网中，因安全性问题可自行设置账户密码
- 安装库：
```bash
pip install -r requirements.txt
```
- 若脚本在Linux操作系统上，使用脚本运行，否则直接用python命令运行scrapper-main.py，或者自己编写批处理文件
```bash
./run_scrapper.sh
```

### TODO

- 目前遇到的问题：论文并非逐天发布，如在2025-02-24时查询2025-02-22的论文，发现不存在论文，导致任务一不能发挥应有的实时更新功能，arXiv发布规律有待研究
- 项目目录结构、代码需优化以增加可读性(如将长函数分装到各个小函数中，减少硬编码等)
- 稳定性：若中途发生崩溃(网络问题、被屏蔽等)，需自重启。需要在服务器上长期运行脚本时，需开机自启动，后续会编写脚本实现。
- *批量下载pdf脚本