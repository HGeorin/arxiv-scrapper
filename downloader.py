import os
import requests
import time
# import tqdm
import logging
from pymongo import MongoClient

logging.basicConfig(filename='./logs/cs-downloader.log', level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# è¿æ¥ MongoDB
client = MongoClient("mongodb://localhost:27017/")
db = client["arxiv"] 
collection = db["cs-paper"]

# æŸ¥è¯¢éœ€è¦ä¸‹è½½çš„è®ºæ–‡
papers = collection.find({"download_mark": 0}, {"arxivId": 1, "file_path": 1})

# ä¸‹è½½ç›®å½•
BASE_DIR = "./paper_storage"

print("downloading files. Press Ctrl + C to cancel ...")

# ä¸‹è½½è¶…æ—¶æ—¶é—´
max_time = 10 * 60  # æœ€å¤§ä¸‹è½½æ—¶é—´

for paper in papers:
    arxiv_id = paper["arxivId"]
    file_path = paper["file_path"]

    # è®ºæ–‡ PDF ä¸‹è½½ URL
    pdf_url = f"https://arxiv.org/pdf/{arxiv_id}.pdf"
    
    # è®ºæ–‡æœ¬åœ°å­˜å‚¨è·¯å¾„
    full_path = os.path.join(BASE_DIR, file_path)

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(full_path), exist_ok=True)

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè‹¥å­˜åœ¨åˆ™åˆ é™¤
    if os.path.exists(full_path):
        os.remove(full_path)

    try:
        # ä¸‹è½½ PDF
        response = requests.get(pdf_url, stream=True, timeout=60)
        if response.status_code == 200:
            download_flag = 1
            with open(full_path, "wb") as pdf_file:
                start_time = time.time()  # è®°å½•å¼€å§‹æ—¶é—´
                for chunk in response.iter_content(chunk_size=1024):
                    # æ£€æŸ¥ä¸‹è½½æ€»æ—¶é•¿
                    elapsed_time = time.time() - start_time
                    if elapsed_time > max_time:  # å¦‚æœä¸‹è½½æ—¶é—´è¶…è¿‡æœ€å¤§é™åˆ¶
                        os.remove(full_path)
                        logging.warning(f"âš ï¸ download timeout and skip: {arxiv_id}")
                        download_flag = 0
                        break
                    pdf_file.write(chunk)
            
            # ä¸‹è½½æˆåŠŸï¼Œæ›´æ–°æ•°æ®åº“
            if download_flag:
                collection.update_one({"arxivId": arxiv_id}, {"$set": {"download_mark": 1}})
                logging.info(f"âœ… download successfully : {full_path}")
        else:
            logging.warning(f"âš ï¸ download failed: {arxiv_id}ï¼Œstatus: {response.status_code}")
    except requests.exceptions.Timeout:
        os.remove(full_path)
        logging.warning(f"âš ï¸ connection timeout and skip: {arxiv_id}")
    except Exception as e:
        logging.error(f"âŒ {arxiv_id}, {e}")
    time.sleep(10)

logging.info("ğŸ“‚ all the papers have been downloaded ")
